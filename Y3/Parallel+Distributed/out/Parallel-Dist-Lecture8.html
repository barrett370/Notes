<!DOCTYPE html><html><head>
      <title>Distributed and Parallel Computing: Lecture 8</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css">
      
      

      
      
      
      
      
      
      

      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="lecture-8">Lecture 8</h1>

<h2 class="mume-header" id="sms-cores-and-warps">SMs, Cores and Warps</h2>

<ul>
<li>A GPU has a number of <em>Streaming Multiprocessors (SMs)</em> which have a number of <em>cores</em>. Threads are scheduled in units of <em>Warps</em></li>
<li>Each SM has a number of resources
<ul>
<li>E.g 400-500 series Nvidia GPUs have:
<ul>
<li>2 Instruction despatch units
<ul>
<li>Each can start, on each clock cycle, processing on any 2 banks at a time. The 3 banks of 16 cores mean that 2 sequential instructions from one thread warp can be executing simultaneously if are not dependent on each other</li>
</ul>
</li>
<li>3 banks of 16 cores (48 cores)</li>
<li>1 bank of 16 load store units
<ul>
<li>for calculating source and destination addresses</li>
</ul>
</li>
<li>1 bank of 4 special functional units
<ul>
<li>hardware support for calculating <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>sin</mi><mo>&#x2061;</mo></mrow><annotation encoding="application/x-tex">\sin</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66786em;vertical-align:0em;"></span><span class="mop">sin</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>&#x2061;</mo></mrow><annotation encoding="application/x-tex">\cos</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mop">cos</span></span></span></span>, reciprocals and square roots</li>
</ul>
</li>
<li>1 bank of 4 texture units</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="gpu-specs">GPU specs:</h2>

<ul>
<li>Global Memory and constant memory is the only GPU memory that you can copy into.
<ul>
<li>constant memory can only be edited by the host</li>
</ul>
</li>
</ul>
<pre data-role="codeBlock" data-info="json" class="language-json">&lt;&lt;  ./deviceQuery
&gt;&gt;  ./DeviceQuery/Debug/deviceQuery Starting...


Device <span class="token number">0</span><span class="token operator">:</span> <span class="token string">&quot;GeForce RTX 2070&quot;</span>
  CUDA Driver Version / Runtime Version          <span class="token number">10.1</span> / <span class="token number">10.1</span>
  CUDA Capability Major/Minor version number<span class="token operator">:</span>    <span class="token number">7.5</span>
  Total amount of global memory<span class="token operator">:</span>                 <span class="token number">7982</span> MBytes (<span class="token number">8370061312</span> bytes)
  (<span class="token number">36</span>) Multiprocessors<span class="token punctuation">,</span> ( <span class="token number">64</span>) CUDA Cores/MP<span class="token operator">:</span>     <span class="token number">2304</span> CUDA Cores
  GPU Max Clock rate<span class="token operator">:</span>                            <span class="token number">1710</span> MHz (<span class="token number">1.71</span> GHz)
  Memory Clock rate<span class="token operator">:</span>                             <span class="token number">7001</span> Mhz
  Memory Bus Width<span class="token operator">:</span>                              <span class="token number">256</span>-bit
  L<span class="token number">2</span> Cache Size<span class="token operator">:</span>                                 <span class="token number">4194304</span> bytes
  Maximum Texture Dimension Size (x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>z)         <span class="token number">1</span>D=(<span class="token number">131072</span>)<span class="token punctuation">,</span> <span class="token number">2</span>D=(<span class="token number">131072</span><span class="token punctuation">,</span> <span class="token number">65536</span>)<span class="token punctuation">,</span> <span class="token number">3</span>D=(<span class="token number">16384</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">,</span> <span class="token number">16384</span>)
  Maximum Layered <span class="token number">1</span>D Texture Size<span class="token punctuation">,</span> (num) layers  <span class="token number">1</span>D=(<span class="token number">32768</span>)<span class="token punctuation">,</span> <span class="token number">2048</span> layers
  Maximum Layered <span class="token number">2</span>D Texture Size<span class="token punctuation">,</span> (num) layers  <span class="token number">2</span>D=(<span class="token number">32768</span><span class="token punctuation">,</span> <span class="token number">32768</span>)<span class="token punctuation">,</span> <span class="token number">2048</span> layers
  Total amount of constant memory<span class="token operator">:</span>               <span class="token number">65536</span> bytes
  Total amount of shared memory per block<span class="token operator">:</span>       <span class="token number">49152</span> bytes
  Total number of registers available per block<span class="token operator">:</span> <span class="token number">65536</span>
  Warp size<span class="token operator">:</span>                                     <span class="token number">32</span>
  Maximum number of threads per multiprocessor<span class="token operator">:</span>  <span class="token number">1024</span>
  Maximum number of threads per block<span class="token operator">:</span>           <span class="token number">1024</span>
  Max dimension size of a thread block (x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>z)<span class="token operator">:</span> (<span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span>)
  Max dimension size of a grid size    (x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>z)<span class="token operator">:</span> (<span class="token number">2147483647</span><span class="token punctuation">,</span> <span class="token number">65535</span><span class="token punctuation">,</span> <span class="token number">65535</span>)
  Maximum memory pitch<span class="token operator">:</span>                          <span class="token number">2147483647</span> bytes
  Texture alignment<span class="token operator">:</span>                             <span class="token number">512</span> bytes
  Concurrent copy and kernel execution<span class="token operator">:</span>          Yes with <span class="token number">3</span> copy engine(s)
  Run time limit on kernels<span class="token operator">:</span>                     No
  Integrated GPU sharing Host Memory<span class="token operator">:</span>            No
  Support host page-locked memory mapping<span class="token operator">:</span>       Yes
  Alignment requirement for Surfaces<span class="token operator">:</span>            Yes
  Device has ECC support<span class="token operator">:</span>                        Disabled
  Device supports Unified Addressing (UVA)<span class="token operator">:</span>      Yes
  Device supports Compute Preemption<span class="token operator">:</span>            Yes
  Supports Cooperative Kernel Launch<span class="token operator">:</span>            Yes
  Supports MultiDevice Co-op Kernel Launch<span class="token operator">:</span>      Yes
  Device PCI Domain ID / Bus ID / location ID<span class="token operator">:</span>   <span class="token number">0</span> / <span class="token number">11</span> / <span class="token number">0</span>

</pre><p><strong>Note:</strong></p>
<ul>
<li>1 core = 1 processing unit and can execute 1 thread</li>
<li>1 Warp = 32 cores</li>
</ul>
<p>Key details from printout above:</p>
<ul>
<li>36 SMs</li>
<li>64 cores/SM (=2304 CUDA cores total)</li>
<li>Maximum of 1024 threads/ SM</li>
<li>Maximum of 1024 threads/block</li>
<li>Maximum GPU clock rate of 1.71 GHz</li>
</ul>
<p>When a <em>kernel</em> is invoked with a configuration of Grid, Blocks and Threads</p>
<ul>
<li>Each block is assigned to a SM (streaming multi-processor) based on availability</li>
<li>Max 1024 threads/block <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>&#x2005;&#x200A;</mtext><mo>&#x27F9;</mo><mtext>&#x2005;&#x200A;</mtext></mrow><annotation encoding="application/x-tex">\implies</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.549em;vertical-align:-0.024em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&#x27F9;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span></span></span> 2 blocks can be <em>in flight</em> on each SM
<ul>
<li>This can be increased by having less threads allocated to each block</li>
</ul>
</li>
<li>When a block is assigned to a SM, the warps of the block are distributed statically among the warp schedulers</li>
<li>With a maximum of 1024 threads/SM (32 warps) each warp scheduler gets at most 8 warps (due to each SM having 4 warp schedulers &lt;&lt; <strong>Check</strong>)</li>
<li>Maximum number of blocks/SM is <strong>??</strong></li>
<li>Each scheduler can issue to to 2 independent instruction from the same warp each cycle</li>
</ul>
<h2 class="mume-header" id="syncronisation">Syncronisation</h2>

<ul>
<li>Warps execute in lock-step
<ul>
<li>so synchronisation within a warp is mostly automatic but (data variables should be marked <code>volatile</code>)</li>
<li>In practice, it is much more complex</li>
<li>We need to be able to synchronise threads in a block</li>
<li>We also need to be able to synchronise threads in a warp</li>
<li>Cannot synchronise across different blocks</li>
<li><strong>Barrier synchronisation:</strong> <code>__syncthreads()</code></li>
<li>Must <strong>Never</strong> have <code>__syncthreads()</code> in a branch of a conditional that some threads in the block will not execute
<ul>
<li>else a deadlock will occur.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="more-on-warps">More on Warps</h2>

<ul>
<li>
<p>For threads in a block</p>
<ul>
<li>Warp 0 consists of threads 0 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&#x2192;</mo></mrow><annotation encoding="application/x-tex">\rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">&#x2192;</span></span></span></span> 31</li>
<li>Warp 1 consists of threads 32 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&#x2192;</mo></mrow><annotation encoding="application/x-tex">\rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">&#x2192;</span></span></span></span> 63</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&#x22EF;</mo></mrow><annotation encoding="application/x-tex">\cdots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.31em;vertical-align:0em;"></span><span class="minner">&#x22EF;</span></span></span></span></li>
</ul>
</li>
<li>
<p>For threads in a mutli-dimensional block</p>
<ul>
<li>Mutlidimensional threads are linearised in a row-major order</li>
<li>Within each group of threads with the same <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span></span></span></span> value, the threads are indexed by their <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> values.</li>
<li>Within each group of threads with the same <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> value the threads are indexed by their <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> values</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="warp-execution-and-divergence">Warp Execution and divergence</h2>

<p>A whole warp is handled by a single controller. Consider what happens if some threads <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\bf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">A</span></span></span></span></span></span> in a warp take one branch, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>, of an <code>if</code> statement and others <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\bf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">B</span></span></span></span></span></span> take the other branch, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>.</p>
<ul>
<li>All threads in the warp must execute the <strong>same</strong> instructions</li>
<li>The first branch, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> : here <strong>all</strong> threads execute branch 1 instructions. However, the threads in group <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\bf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">B</span></span></span></span></span></span> are disabled (analogous to de-clutching a car)</li>
<li>Then execute branch <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>: again, all threads execute the instructions but branch <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\bf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">A</span></span></span></span></span></span> threads are disabled.</li>
<li>This is called <em><strong>divergence</strong></em></li>
<li>The whole warp execute the same branch <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>&#x2005;&#x200A;</mtext><mo>&#x27F9;</mo><mtext>&#x2005;&#x200A;</mtext></mrow><annotation encoding="application/x-tex">\implies</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.549em;vertical-align:-0.024em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&#x27F9;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span></span></span> <em><strong>NO Divergence</strong></em></li>
</ul>
<p>Loops where different threads in the warp execute different numbers of iterations also form divergences. I.e. the threads that conceptually execute the lowest number of iterations <strong>actually</strong> execute the same as the rest of the threads, conceptually the same as the threads executing the most iterations.</p>
<h2 class="mume-header" id="divergence-and-reduction">Divergence and Reduction</h2>

<p>Now we will look at the consequences of divergence for the process of reducing a set of numbers to 1. E.g. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>&#x2211;</mo><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><mn>1024</mn></msubsup><mi>x</mi></mrow><annotation encoding="application/x-tex">\sum_{x=1}^{1024}x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.253718em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">&#x2211;</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954008em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">2</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span></span></span></span></p>
<ul>
<li>Sequentially we would solve this by iterating through a vector, accumulating the sum in a variable</li>
<li>In parallel, one approach would be to use a <em>binary tournament</em>:
<ul>
<li>Round 1:
<ul>
<li>thread 0 executes <code>A[0] += A[1]</code></li>
<li>thread 2 executes <code>A[2] += A[3]</code></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&#x22EF;</mo></mrow><annotation encoding="application/x-tex">\cdots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.31em;vertical-align:0em;"></span><span class="minner">&#x22EF;</span></span></span></span></li>
<li>thread <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>i</mi></mrow><annotation encoding="application/x-tex">2i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathdefault">i</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mn>2</mn><mi>i</mi><mo>&lt;</mo><mn>1024</mn></mrow><annotation encoding="application/x-tex">0&lt;2i&lt;1024</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68354em;vertical-align:-0.0391em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69862em;vertical-align:-0.0391em;"></span><span class="mord">2</span><span class="mord mathdefault">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span></span></span></span>, executes <code>A[2*i] += A[2*i+1]</code></li>
</ul>
</li>
<li>Round 2:
<ul>
<li>thread <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>i</mi></mrow><annotation encoding="application/x-tex">4i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord mathdefault">i</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mn>4</mn><mi>i</mi><mo>&lt;</mo><mn>1024</mn></mrow><annotation encoding="application/x-tex">0&lt;4i&lt;1024</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68354em;vertical-align:-0.0391em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69862em;vertical-align:-0.0391em;"></span><span class="mord">4</span><span class="mord mathdefault">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span></span></span></span>, executes <code>A[4*i] += A[4*i+2]</code></li>
</ul>
</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&#x22EF;</mo></mrow><annotation encoding="application/x-tex">\cdots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.31em;vertical-align:0em;"></span><span class="minner">&#x22EF;</span></span></span></span></li>
<li>Round <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span>
<ul>
<li>thread <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup><mi>i</mi></mrow><annotation encoding="application/x-tex">2^ni</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.664392em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span><span class="mord mathdefault">i</span></span></span></span> executes <code>A[pow(2,n)*i] += A[pow(2,n)*i+pow(2,n-1)]</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Diagrammatically, this would look like:</p>
<p><img src="../resources/naive-parallel-reduction.png?0.586751518629606" alt></p>
<p>This could be implemented as follows:</p>
<pre data-role="codeBlock" data-info="cpp" class="language-cpp"><span class="token keyword">float</span> partialSum<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
uint t <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>uint stride <span class="token operator">=</span> <span class="token number">1</span> <span class="token punctuation">;</span> stride <span class="token operator">&lt;</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span> stride <span class="token operator">*=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
  <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>t <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> stride<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
    partialSum<span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">+=</span> partialSum<span class="token punctuation">[</span>t<span class="token operator">+</span>stride<span class="token punctuation">]</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</pre><ul>
<li>Assume <code>blockDim.x = 1024</code></li>
<li><code>__syncthreads()</code> is required to make sure all threads have completed the previous stage before continuing</li>
<li>In first pass, all warps are active but only half the threads are doing useful work. This only gets worse on future iterations</li>
</ul>
<p>Diagrammatically an alternative, more efficient, method could look like:</p>
<p><img src="../resources/alternative-parallel-scan.png?0.6781224375194588" alt></p>
<p>with the corresponding code looking like:</p>
<pre data-role="codeBlock" data-info="cpp" class="language-cpp"><span class="token keyword">float</span> partialSum<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
uint t <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>uint stride <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x<span class="token operator">/</span><span class="token number">2</span> <span class="token punctuation">;</span> stride <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token punctuation">;</span> stride <span class="token operator">&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
  <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>t<span class="token operator">&lt;</span>stride<span class="token punctuation">)</span><span class="token punctuation">{</span>
    partialSum<span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">+=</span> partialSum<span class="token punctuation">[</span>t<span class="token operator">+</span>stride<span class="token punctuation">]</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</pre><ul>
<li>Again, assuming that <code>blockDim.x = 1024</code></li>
<li>Here however, threads 0-511 (warps 0-15) execute the true branch with threads 512-1023 executing the false branch, this leads to no divergence, therefore 1 pass each iteration</li>
<li>Continues 1 pass each iteration until there are less than 32 threads executing</li>
</ul>
<h2 class="mume-header" id="memory-bandwidth-as-a-performance-barrier">Memory Bandwidth as a Performance Barrier</h2>

<ul>
<li>For simple operations such as <em>vectorAdd</em> the <em>compute to global memory access ratio</em> or CGMA is 1/3, i.e. 1 flop per 3 memory accesses</li>
<li>Assume the global memory access bandwidth is in the range of 200GB/s and the processor can execute around 1500 GFLOPS then the memory bandwidth is limiting us in the following way:
<ul>
<li>3 read/writes = 12 bytes</li>
<li>12 bytes memory access at 200GB/s for each flop = 200/12 GFLOPS = 17 GFLOPS</li>
<li>Therefore, although the hardware is capable fo 1500GFLOPS, our global memory limits us to just 17 GFLOPS</li>
</ul>
</li>
</ul>
<p>Applying this to our parallel reduction:</p>
<ul>
<li>Each reduction reads 2 words from global memory and wrtites one word back to global memory per working thread</li>
<li>If instead the first read copied from global <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&#x2192;</mo></mrow><annotation encoding="application/x-tex">\rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">&#x2192;</span></span></span></span> shared memory, the remainder of the operation would be <strong>much</strong> faster</li>
<li>In general, many such operations exist whereby, a large problem can be broken into small <em>tiles</em>, each of which fits into shared memory, the tiles can be worked on and combined at the very end for a much faster overall calculation.</li>
</ul>

      </div>
      <div class="md-sidebar-toc"><ul>
<li><a href="#lecture-8">Lecture 8</a>
<ul>
<li><a href="#sms-cores-and-warps">SMs, Cores and Warps</a></li>
<li><a href="#gpu-specs">GPU specs:</a></li>
<li><a href="#syncronisation">Syncronisation</a></li>
<li><a href="#more-on-warps">More on Warps</a></li>
<li><a href="#warp-execution-and-divergence">Warp Execution and divergence</a></li>
<li><a href="#divergence-and-reduction">Divergence and Reduction</a></li>
<li><a href="#memory-bandwidth-as-a-performance-barrier">Memory Bandwidth as a Performance Barrier</a></li>
</ul>
</li>
</ul>
</div>
      <a id="sidebar-toc-btn">&#x2261;</a>
    
    
    
    
    
    
    
    
<script>

var sidebarTOCBtn = document.getElementById('sidebar-toc-btn')
sidebarTOCBtn.addEventListener('click', function(event) {
  event.stopPropagation()
  if (document.body.hasAttribute('html-show-sidebar-toc')) {
    document.body.removeAttribute('html-show-sidebar-toc')
  } else {
    document.body.setAttribute('html-show-sidebar-toc', true)
  }
})
</script>
      
  
    </body></html>