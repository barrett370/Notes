<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Modules on Welcome to my Notes Repo!</title>
    <link>https://sam-barrett.codes/Notes/modules/</link>
    <description>Recent content in Modules on Welcome to my Notes Repo!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 05 Jan 2020 16:15:47 +0000</lastBuildDate>
    
	<atom:link href="https://sam-barrett.codes/Notes/modules/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Distributed and Parallel Computing</title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/pd-index/</link>
      <pubDate>Sun, 05 Jan 2020 16:15:47 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/pd-index/</guid>
      <description> Lecture 1 Lecture 2 Lecture 3 Lecture 4 Lecture 5 Lecture 6 Lecture 7 Lecture 8 Lecture 9 Lecture 10 Lecture 12  </description>
    </item>
    
    <item>
      <title>Machine Learning</title>
      <link>https://sam-barrett.codes/Notes/modules/machine-learning/ml-index/</link>
      <pubDate>Sun, 05 Jan 2020 16:15:47 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/machine-learning/ml-index/</guid>
      <description> Lecture 1 Lecture 2 Lecture 3 Lecture 4 Lecture 5 Lecture 6 Lecture 7 Lecture 8 Lecture 9 Lecture 10 Lecture 11 Lecture 12  </description>
    </item>
    
    <item>
      <title>Neural Computation</title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/nc-index/</link>
      <pubDate>Sun, 05 Jan 2020 16:15:47 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/nc-index/</guid>
      <description> Lecture 1 Lecture 2 Lecture 3 Lecture 4 Lecture 5 Lecture 6 Lecture 7 Lecture 8 Lecture 9 Lecture 10  </description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/machine-learning/lectures/ml-lecture1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/machine-learning/lectures/ml-lecture1/</guid>
      <description>ML-Lecture1  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/machine-learning/lectures/ml-lecture2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/machine-learning/lectures/ml-lecture2/</guid>
      <description>ML-Lecture2  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/machine-learning/source/ml-lecture1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/machine-learning/source/ml-lecture1/</guid>
      <description>Lecture 1 Regression  The task of finding the relationship (mathematical function) between one or more numerical inputs (independent variables) and one or more numerical outputs (dependent variables)
 Curve fitting
 Given a set of points, try ot learn a function to describe them Given a value $x$, we can predict the corresponding value $y$ Not just for straight line fitting   Simple example Let us consider a simple linear example with 1 independent variable, $x$ &amp;amp; 1 dependent variable, $y$</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/machine-learning/source/ml-lecture2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/machine-learning/source/ml-lecture2/</guid>
      <description>Lecture 2: Model Bias &amp;amp; Variance Noisy Data &amp;amp; Overfitting Data can introduce challenges into our model fitting algorithms. Given a model that is too expressive ,i.e. too high dimensionality, our model may overfit and instead of just capturing the underlying pattern/ equation, it may also fit the noise.
To show this we will use the equation
(1) $$y(x) = \sin(2\pi x)$$
Clearly if we were to set our basis functions to $\phi = {sin(2\pi x)}$ we could easily fit with one dimension $w_0 = 1$ resulting in $f(\textbf{w},x)= w_0\sin(2\pi x)$ However, we will look at a more generalised approach as in most practical applications we would not have, $a)$ such an obvious underlying function or $b)$ the underlying function known to us.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture1/</guid>
      <description>Neural-Comp-Lecture1  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture10/</guid>
      <description>Neural-Comp-Lecture10  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture11/</guid>
      <description>Neural-Comp-Lecture11  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture2/</guid>
      <description>Neural-Comp-Lecture2  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture3/</guid>
      <description>Neural-Comp-Lecture3  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture4/</guid>
      <description>Neural-Comp-Lecture4  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture5/</guid>
      <description>Neural-Comp-Lecture5  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture6/</guid>
      <description>Neural-Comp-Lecture6  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture7/</guid>
      <description>Neural-Comp-Lecture7  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture8/</guid>
      <description>Neural-Comp-Lecture8  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/lectures/neural-comp-lecture9/</guid>
      <description>Neural-Comp-Lecture9  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture1/</guid>
      <description>Lecture 1 Definition of Machine Learning A Computer Program is said to learn from experience, E, with respect to some class of task, T, and performance, P if it&amp;rsquo;s performance as tasks in T improves, as measured by P with experience E
Tasks, $T$ Classification  Construct a function, $f : \R^n \rightarrow { 1,&amp;hellip;,k }$, s.t. if an object with features $x \in \R^n $ belongs to class , y, then $f(x) = y$ Alternatively, Construct a function which given features returns the probability of each class  Regression  Predict a numerical value given some inputs, i.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture10/</guid>
      <description>Lecture 10 Model Capacity Informally, the Model Capacity is a model&amp;rsquo;s capacity to fit a wide range of functions. In statistical learning theory, model capacity is quantified by *VC-Dimension: Largest training set for which the model cna classify the labels arbitrarily into two classes By the universal approximation theorem, neural networks can have a very high capacity see previous lecture
Underfitting &amp;amp; Overfitting Underfitting: Too high a training error Overfitting: Too large a gap between training error and test error</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture11/</guid>
      <description>Lecture 11: Deep Learning Linear Regression - Revisit In linear regression problems we have the following:
 Our data, $(x_1,y_1),\ldots, (x_n,y_n)$ Our model, $y = \textbf{w}x + \textbf{b}$ A loss function, often the mean squared error:  $$ L(x,\theta) = \sum_{i=1}^{n}|(\textbf{w}x_i + \bf{b}) - y_i|^2 $$
Where, $\theta = { \textbf{w},\textbf{b}}$
 An optimiser with underlying optimisation function, often gradient descent:  $$ \boldsymbol{\theta}^{j+1} = \boldsymbol{\theta}^j - \nabla_\theta L(x,\boldsymbol{\theta}^j) $$</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture2/</guid>
      <description>Lecture 2 Linear Regression Models Cat Hearts example: Experience $E$  The dataset consists of $n$ data points  $((x_1,y_1),&amp;hellip;,(x_n,y_n)\in \R^d\times \R)$ $x_i \in \R^d$ is the &amp;ldquo;input&amp;rdquo; for the $i^{th}$ data point as a feature vector with $d$ elements, $d$ being the # of dimensions in the feature space, in this case 1. $y_i \in \R$ is the &amp;ldquo;output&amp;rdquo; for the $i^{th}$ data point, in this case the weight of the corresponding cat heart.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture3/</guid>
      <description>Lecture 3: Maximum Likelihood  So far we have considered a deterministic model, $f(x) = wx$    However, we can see that there is variation in the data for each value of $x$ A probabilistic model can account for this variance  e.g. $F(x) = wx + N$ where: $N \sim \mathcal{N}(0,\sigma^2)$ is a noise term $F(X)$ is a random variable which can be described by a conditional density $P(y | x, w)$    An aside into basic probability Probability Density Functions  A random variable takes a value that depends on a random phenomenon The density function ofa continuous random variable $X$ is a function $p : \R \rightarrow \R$ s.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture4/</guid>
      <description>Lecture 4  So far we have only looked at models with 1 parameter  (1) $$ J(\Theta) = \mathbb{E}{\mathcal{X,Y}\sim \mathcal{D}}-\log{Pmodel}(\mathcal{Y | X; \Theta)}$$
 We will nw look at models with many variables  Functions of multiple variables Vectors  Vectors are &amp;ldquo;arrays&amp;rdquo; of numbers e.g.  (2) $$\vec{v} = \langle v_1, \cdots, v_n \rangle \in \R^n$$
 We can consider a vector as a point i a $n$ dimensional space where each point $v_i$ gives the coordinate along the $i^{th}$ axis.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture5/</guid>
      <description>Lecture 5 Computation Graphs We will describe ML models using computation graphs where
 Nodes represent variables (values, vectors, matrices) Edges represent functional dependencies  i.e. an edge from $x$ to $y$ indicates that $y$ is a function of $x$   Example The linear regression model, $z = \sum_{i=1}^m a_iw_i+b$ could be represented as:
Feed-Forward Neural Network Stepping it up, here is a simple Feed-forward Neural Network:
Where:</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture6/</guid>
      <description>Lecture 6 Softmax In Lecture 5 we derived the per-example cost function:
$$Ci = \sum{j=1}^m\frac{1}{2}(y_j^{(i)} -a_j^L)^2 \tag{1}$$
where $a_j^L$ is the output of the model
Using the maximum likelihood method under the assumption that the predicted output $a_j^L$ has a Gaussian (normal) distribution. This assumption is acceptable for regression problems
However, when we look at classification problems with $m$ discrete class labels ${1,\cdots m}$ it makes more sense to have one output unit $P_j$ per class, $j$ where $P_j$ is the probability of the example falling into class $j$</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture7/</guid>
      <description> Lecture 7 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture8/</guid>
      <description>Lecture 8 Repetition: Gradient Descent In gradient descent we have an input of a cost function, $\mathcal{J}$ and a learning rate, $\varepsilon$
$$ \mathcal{J} : \R^m \rightarrow \R $$
The pseudo-code for conventional gradient decent is as follows:
foo
$$ x\leftarrow \text{some initial point in } \R^m \text{while termination condition not met} \ { x \leftarrow x - \varepsilon \cdot \nabla \mathcal{J}(x) \ } $$
Impact of learning rate $\varepsilon$ on Stochastic Gradient Descent  Learning rate in SGD can have a marked impact on the optimisation time of a network Often necessary to vary/ adjust the learning rate according to the specific model you are training.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/neural-computation/source/neural-comp-lecture9/</guid>
      <description>Lecture 9 Previously, we looked at different optimisation algorithms.
Generalisation in Neural Networks Hypothesis:
 Neural Networks generalise from the training data, i.e. by learning the inherent structure in the data.
 Test of Hypothesis: removing structure should reduce network performance
Zhang et al. (ICLR 2017) trained a network over the CIFAR10 dataset with the following settings:
 True labels, original training set (ground) Random labels: all labels are replaced with random ones Shuffle pixels: a random permutation of the pixels for each image Gaussian: A gaussian distribution is used to generate random pixels for each image   Deep neural networks easily fit random labels The effective capacity of neural networks is sufficient for memorising the entire dataset Training time increases only by a small constant factor  Perceptrons These were a very early form of artificial networks and are comparatively very weak to current approaches</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/lab-ex1-report/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/lab-ex1-report/</guid>
      <description>REPORT  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture1/</guid>
      <description>Parallel-Dist-Lecture1  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture10/</guid>
      <description>Parallel-Dist-Lecture10  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture12/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture12/</guid>
      <description>Parallel-Dist-Lecture12  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture2/</guid>
      <description>Parallel-Dist-Lecture2  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture3/</guid>
      <description>Parallel-Dist-Lecture3  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture4/</guid>
      <description>Parallel-Dist-Lecture4  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture5/</guid>
      <description>Parallel-Dist-Lecture5  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture6/</guid>
      <description>Parallel-Dist-Lecture6  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture7/</guid>
      <description>Parallel-Dist-Lecture7  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture8/</guid>
      <description>Parallel-Dist-Lecture8  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-dist-lecture9/</guid>
      <description>Parallel-Dist-Lecture9  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture1/</guid>
      <description>Parallel-Dist-Lecture1  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture10/</guid>
      <description>Parallel-Dist-Lecture10  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture12/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture12/</guid>
      <description>Parallel-Dist-Lecture12  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture2/</guid>
      <description>Parallel-Dist-Lecture2  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture3/</guid>
      <description>Parallel-Dist-Lecture3  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture4/</guid>
      <description>Parallel-Dist-Lecture4  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture5/</guid>
      <description>Parallel-Dist-Lecture5  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture6/</guid>
      <description>Parallel-Dist-Lecture6  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture7/</guid>
      <description>Parallel-Dist-Lecture7  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture8/</guid>
      <description>Parallel-Dist-Lecture8  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/lectures/parallel-distributed-lecture9/</guid>
      <description>Parallel-Dist-Lecture9  /** * prism.js Github theme based on GitHub&#39;s theme. * @author Sam Clarke */ code[class*=&#34;language-&#34;], pre[class*=&#34;language-&#34;] { color: #333; background: none; font-family: Consolas, &#34;Liberation Mono&#34;, Menlo, Courier, monospace; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; word-wrap: normal; line-height: 1.4; -moz-tab-size: 8; -o-tab-size: 8; tab-size: 8; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; } /* Code blocks */ pre[class*=&#34;language-&#34;] { padding: .8em; overflow: auto; /* border: 1px solid #ddd; */ border-radius: 3px; /* background: #fff; */ background: #f5f5f5; } /* Inline code */ :not(pre)  code[class*=&#34;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture1/</guid>
      <description>Lecture 1 Moore&amp;rsquo;s Law &amp;ldquo;The number of transistors in a dense integrated circuit will double exponentially every 2 years&amp;rdquo; -Gordon Moore 1965
 Not technically a &amp;ldquo;law&amp;rdquo; but an observation $\rightarrow$ prediction. True more-or-less until 2012, now slowing down. Processor clock rates stopped increasing in the early 2010s due to heat dispersion issues. As we cannot increase performance via clock rate, we instead increase transistor count to put multiple processors on the same chip to ger more work done via parallelism.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture10/</guid>
      <description>Lecture 10 Common CUDA Programming Errors  malloc, cudaMalloc and cudaMemcpy take arguments specified in bytes
 Make sure you read kernel code, i.e code specified as __global__ or __shared__ as if it is being run mutiple times concurrently
 Read/Write race conditions, e.g if the following code is being run on multiple threads at the same time
__global__ kern(int *A, int len){ int i = blockDim.x * blockIdx.x + threadIdx.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture12/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture12/</guid>
      <description>Lecture 12 GPU Sorting Merge sort on NVidia GPUs In order to make good use of the hardware we consider 3 stages:
 Many small sequences  Each less than one block size Here there are many small merges to do Each thread can do 1 merge Each block handles many merges Memory coalescing: better &amp;hellip;   Bitonic Sort  A comparitor is a function that swaps two elements if they are in th wrong order A monotonic increasing/decreasing sequence is one where very element is equal to or greater/less than every preceding element A bitonic sequence is a sequence which changes order direct at most once, or a circular shift of such a sequence.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture2/</guid>
      <description>Lecture 2 Measuring Speed  Most CPU clocks can&amp;rsquo;t be more accurate than 10ms At 3GHz, 10ms = 30,000,000 cycles  ~1$\rightarrow$5 cycles per instruction $\therefore$ 10ms $\approx$ 10,000,000 instructions  Code that takes 15ms is reported as having taken 10 or 20 ms
 Large inaccuracy 10ms $\pm$ 10ms  Instead, run it 100 times, 1500 ms reported as either 1490, 1500 or 1510
 lower relative inaccuracy  Issue: compilers are too smart, and will attempt to optimise re-runs, therefore, subsequent runs may be much faster than initial</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture3/</guid>
      <description>Lecture 3 DRAM Access Patterns    Rule Ideal Values Description     Granularity 6 - 64 B Amount of data transferred in a single request     Reading smaller sizes is very inefficient   Locality 1- 4kB If you use an address now, you will likely use it again soon (fetch from cache, not memory)     If you use an address now, you will likely use one close to it soon (In same cache line, if realated objects are stored too far away from eachother, the cache line can be flushed causing a memory read (inefficient)   L1, L2 caching 64-256 kB Set of bytes read/written repeatedly is stored here until replaced, subsequent reads and writes hit the cache not memory, much faster.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture4/</guid>
      <description>Lecture 4  Lecture 4  Threads Threads in Java  Creating a Thread Example of a Runnable Class Instantiating a Thread  Monitors Concurrent access Queue Implementation Mutual Exclusion Waiting Spinning Blocking The wait() method  Usage  Awakening Thread local data Thread local data in Java  Thread local methods  Thread local IDs   Threads  Execute a sequential series of instructions You can tell a thread  What to do When to start  You can  Wait for it to finish Interrupt it Give it priority over other threads   Threads in Java  Implemented in the java.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture5/</guid>
      <description>Lecture 5 Mutual Exclusion Events  An event $a_0$ of thread $A$ is  Instantaneous Even if two events attempt to execute at exactly the same moment in time, one will execute before the other. Has no simultaneous events    A thread $A$ is a sequence, $(a_0,\cdots)$ of events  $a_0 \prec a_1$ indicates order or precedence    Thread events include the following:  Assign to shared variable Assign to local variable Method invocation Method return  Essentially every low level operation is a thread event.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture6/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture7/</guid>
      <description>Lecture 7 2 Types of Parallelism  Task based  e.g. multiply or add suitable for standard multi-core CPUs or networks of computers i.e. have the same code running on multiple cores or CPUs  Data based  e.g. alter an image by performing hte same operation on each pixel in parallel Suitable for GPUs   Latency vs. Throughput  Latency oriented processors
 Minimises delay on first result being returned e.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture8/</guid>
      <description>Lecture 8 SMs, Cores and Warps  A GPU has a number of Streaming Multiprocessors (SMs) which have a number of cores. Threads are scheduled in units of Warps Each SM has a number of resources  E.g 400-500 series Nvidia GPUs have: 2 Instruction despatch units  Each can start, on each clock cycle, processing on any 2 banks at a time. The 3 banks of 16 cores mean that 2 sequential instructions from one thread warp can be executing simultaneously if are not dependent on each other  3 banks of 16 cores (48 cores) 1 bank of 16 load store units  for calculating source and destination addresses  1 bank of 4 special functional units  hardware support for calculating $\sin$, $\cos$, reciprocals and square roots  1 bank of 4 texture units    GPU specs:  Global Memory and constant memory is the only GPU memory that you can copy into.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sam-barrett.codes/Notes/modules/parallel-distributed/source/parallel-dist-lecture9/</guid>
      <description> Lecture 9 </description>
    </item>
    
  </channel>
</rss>