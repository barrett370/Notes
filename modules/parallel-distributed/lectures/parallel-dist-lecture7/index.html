<!DOCTYPE html><html><head>
      <title>Parallel-Dist-Lecture7</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css">
      
      

      
      
      
      
      
      
      

      <style>
       
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

 
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
   
  border-radius: 3px;
   
  background: #f5f5f5;
}

 
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


 
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

 
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

 
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

 
.language-ruby .token.function {
  color: #333;
}

 
.language-markdown .token.url {
  color: #795da3;
}

 
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

 
.language-bash .token.keyword {
  color: #0086b3;
}

 
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
 
 

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="lecture-7">Lecture 7</h1>

<h2 class="mume-header" id="2-types-of-parallelism">2 Types of Parallelism</h2>

<ul>
<li>Task based
<ul>
<li>e.g. multiply or add</li>
<li>suitable for standard multi-core <strong>CPUs</strong> or networks of computers
<ul>
<li>i.e. have the same code running on multiple cores or <strong>CPUs</strong></li>
</ul>
</li>
</ul>
</li>
<li>Data based
<ul>
<li>e.g. alter an image by performing hte same operation on each pixel in parallel</li>
<li>Suitable for <strong>GPUs</strong></li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="latency-vs-throughput">Latency vs. Throughput</h2>

<ul>
<li>
<p>Latency oriented processors</p>
<ul>
<li>Minimises delay on <strong>first</strong> result being returned</li>
<li>e.g. if an operation takes 4 cycles, 10 operations will take 40 cycles</li>
<li>Large Caches to speed up memory access
<ul>
<li>Temporal/ Spacial locality, working sets</li>
</ul>
</li>
<li>Complex control units
<ul>
<li>Short pipelines, branch prediction, data forwarding
<ul>
<li>to prevent pipeline stalls</li>
</ul>
</li>
</ul>
</li>
<li>Complex, energy expensive ALUs
<ul>
<li>To minimise cycles to return a result.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Throughput oriented processors</p>
<ul>
<li>Minimises delay on <strong>all</strong> results being returned</li>
<li>e.g. implement pipelined operation on ALUs, 10 cycles for first operation and to fill the pipeline but 1 cycles for all subsqeuent operations, total 19 cycles</li>
<li>Small caches
<ul>
<li>For <em>staging</em> data
<ul>
<li>get blocks of data at one time for a group of threads to work on</li>
<li>avoids each thread making separate fetches</li>
</ul>
</li>
</ul>
</li>
<li>Simple control units
<ul>
<li>No branch predction or data forwarding</li>
<li>The control is shared between threads working on different data</li>
</ul>
</li>
<li>Simple, energy efficient ALU
<ul>
<li>Long pipelines</li>
<li>Large number of cycles per operation but heavily pipelined
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&#x2192;</mo></mrow><annotation encoding="application/x-tex">\rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">&#x2192;</span></span></span></span> long wait for first result as pipeline needs to be filled
<ul>
<li>but following results come quickly</li>
</ul>
</li>
<li>Required large amount of threads to keep processor occupied</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h6 class="mume-header" id="fig-1-von-neumann-architecture">Fig. 1. Von Neumann Architecture</h6>

<div style="text-align:center"><img src="../resources/von-neumann.jpg"></div>
<h6 class="mume-header" id="fig-2-von-neumann-architecture-for-gpu">Fig. 2. Von Neumann Architecture for GPU</h6>

<div style="text-align:center"><img src="../resources/vn-gpu.png"></div>
<h2 class="mume-header" id="compiling-for-cuda">Compiling for CUDA</h2>

<ul>
<li>The host CPU and GPU are separate devices connected by a bus</li>
<li>Each have separate memory</li>
<li>Therefore, we need to generate separate code for each device
<ul>
<li>The nvidia compiler for CUDA programs is <code>nvcc</code></li>
</ul>
</li>
<li><code>nvcc</code> takes <em>C/C++</em> code for with Nvidia extensions, separates and compiles the GPU code and passes the CPU code to the host to be compiled</li>
<li>This results in a single binary with both CPU and GPU code, the GPU code is loaded onto it when the host runs this.</li>
</ul>
<h2 class="mume-header" id="vectoradd-trivial-example">VectorAdd - trivial example</h2>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>C</mi><mo>&#x20D7;</mo></mover><mo>=</mo><mover accent="true"><mi>A</mi><mo>&#x20D7;</mo></mover><mo>+</mo><mover accent="true"><mi>B</mi><mo>&#x20D7;</mo></mover></mrow><annotation encoding="application/x-tex">\vec C = \vec A + \vec B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9663299999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9663299999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.15216em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0496599999999998em;vertical-align:-0.08333em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9663299999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault">A</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.09660999999999997em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.9663299999999999em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9663299999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.15216em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span></span></span></span></span></p>
<p>The sequential code for this may look like this:</p>
<pre data-role="codeBlock" data-info="c" class="language-c"><span class="token keyword">void</span> <span class="token function">vecAdd</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> h_A<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> h_B<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> h_C<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> i<span class="token operator">&lt;</span>n <span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
        h_C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> h_A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> h_B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
    <span class="token comment">// declarations</span>
    <span class="token function">vecAdd</span><span class="token punctuation">(</span>h_A<span class="token punctuation">,</span>h_B<span class="token punctuation">,</span> h_C<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>   
<span class="token punctuation">}</span>
</pre><p>To write this for CUDA we must identify whether a function runs on the host, the device or both.<br>
We also have to work out where it should be callable from:</p>
<ul>
<li>the host: <code>__host__ void f(...)</code>
<ul>
<li>This is default so can be omitted</li>
<li>Callable from the <strong>host only</strong></li>
</ul>
</li>
<li>The device: <code>__global__ void f(...)</code>
<ul>
<li>special functions called <strong>kernel functions</strong></li>
<li>callable from <strong>host only</strong>. This is how we run code on the GPU</li>
</ul>
</li>
<li>The device: <code>__device__ void f(...)</code>
<ul>
<li>callable from the <strong>device only</strong>. they are helper functions</li>
</ul>
</li>
<li>both: <code>__host__ __device__ void f(...)</code></li>
</ul>
<h2 class="mume-header" id="cpu-computational-unit-structure">CPU computational unit structure</h2>

<ul>
<li>When we call a kernel function we need to specify how the threads should be organised to execute it
<ul>
<li>Every thread is going to exectue the same kernel.</li>
<li>Different CPU devices can support different numbers of simultaneously executable threads</li>
<li>Within a GPU thread structure is <strong>not</strong> uniform, i.e. do not have equal access to all the GPU memory, syncronise with other processing units or share cache memory</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="cuda-thread-issues">CUDA thread issues</h2>

<ul>
<li>We don&apos;t want the fixed number of GPU threads to dictate the size of the largest vectors we can add</li>
<li>We don&apos;t want to have to change our code to run on different GPUs</li>
<li>We need to organise our threads to co-locate groups of threads on sets of processing units to take advantage of shared caches and syncronisation facilities</li>
<li>NVidia GPUs accomplish this by organising threads into a hierarchical structure
<ul>
<li>A <em>Grid</em> is a collection of <em>Blocks</em></li>
<li>A <em>Block</em>  is a collection of <em>Threads</em></li>
<li>A <em>Thread</em> is the execution of a <em>kernel</em> on a single processing unit</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="cuda-thread-organisation">CUDA thread organisation</h2>

<p>Outside the <em>Grid/Block/THread</em> hierarchy, there is the concept of a <em>Warp</em></p>
<ul>
<li>
<p>A <em>Warp</em> is a set of a number of tightly related threads that must execute fully in lock step with each other.</p>
</li>
<li>
<p>Warps are not part of CUDA but are on all modern Nvidia GPUs, dictated by low level hardware design</p>
</li>
<li>
<p>The number of threads in a <em>warp</em> is a feature of a particular GPU, but is most commonly 32</p>
</li>
<li>
<p>Warps are the low-level basis of thread scheduling on a GPU, if a thread is scheduled to execute, so are all other threads in the <em>warp</em></p>
</li>
<li>
<p>As they execute the same instructions in lock step, all threads in a <em>warp</em> will have the same instruction timing</p>
</li>
<li>
<p>A block can have a size between 1 and the number of threads on the GPU. (typically 2014) and is the high-level basis of thread scheduling</p>
</li>
<li>
<p>Because of the nature of <em>warps</em>, the block size should be a multiple of the <em>warp</em> size</p>
</li>
<li>
<p>Grids can have large numbers of blocks, many more than can be concurrently executed.</p>
</li>
</ul>
<h2 class="mume-header" id="invoking-kernel-functions">Invoking Kernel Functions</h2>

<ul>
<li>We need to specify the grid/block structure hwen invoking a kernel function</li>
</ul>
<pre data-role="codeBlock" data-info="c" class="language-c"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">int</span> threadsPerBlock <span class="token operator">=</span> <span class="token number">256</span><span class="token punctuation">;</span>
<span class="token keyword">int</span> blocksPerGrid <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>numElements <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> threadsPerBlock<span class="token punctuation">;</span>
vectorAdd<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>blocksPerGrid<span class="token punctuation">,</span> threadsPerBlock <span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_A<span class="token punctuation">,</span> d_B<span class="token punctuation">,</span> d_C<span class="token punctuation">,</span> numElements<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</pre><p><strong>Note <code>&lt;&lt;&lt;blocksPerGrid, threadsPerBlock &gt;&gt;&gt;</code> is not standard C/C++ and is handled by <code>nvcc</code></strong></p>
<h2 class="mume-header" id="inside-kernel-functions">Inside Kernel Functions</h2>

<p>Each thread needs to know which part of the data to work on.<br>
CUDA provides predefined variables for this purpose:</p>
<ul>
<li><code>blockIdx.x</code> the unique identifier for this block in this grid</li>
<li><code>blockDim.x</code> the number of threads in a block for this grid</li>
<li><code>threadIdx.x</code> the unique identifier of this thread in this block</li>
</ul>
<pre data-role="codeBlock" data-info="c" class="language-c">__global__ <span class="token keyword">void</span> 
<span class="token function">vectorAdd</span><span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{</span>
    <span class="token keyword">int</span> i <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> n<span class="token punctuation">)</span><span class="token punctuation">{</span>
        C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</pre><h2 class="mume-header" id="grid-and-block-dimensionalities">Grid and Block Dimensionalities</h2>

<ul>
<li>Grids and Blocks can be organised as 1D, 2D or 3D spaces</li>
<li>Hence the predefined variables <code>blockIdx.x, blockDim.x, threadIdx.x</code> have <code>.y</code> and <code>.z</code> variants
<ul>
<li>If you are using 1D grids and blocks then you can ignore these.</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="device-global-memory">Device Global Memory</h2>

<ul>
<li>GPU memory is <strong>not</strong> shared with the host. Therefore, the host has to copy data to the device and copy s back when the kernel finishes.</li>
<li>Before doing this, the host must allocate global memory on the device and, afterwards, free it again, like <code>malloc</code> and <code>free</code>.
<ul>
<li><strong>Note: the return of <code>cudaMalloc</code> is an error number</strong></li>
</ul>
</li>
</ul>
<pre data-role="codeBlock" data-info="c" class="language-c"><span class="token keyword">float</span> <span class="token operator">*</span>h_A <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">float</span> <span class="token operator">*</span>h_B <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">float</span> <span class="token operator">*</span>d_A <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
err <span class="token operator">=</span> <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_A<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">float</span> <span class="token operator">*</span>d_C <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
err <span class="token operator">=</span> <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_C<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
err <span class="token operator">=</span> <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_A<span class="token punctuation">,</span>h_A<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment">// Invoke kernel</span>
err <span class="token operator">=</span> <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>h_c<span class="token punctuation">,</span>d_C<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
err <span class="token operator">=</span> <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_A<span class="token punctuation">)</span><span class="token punctuation">;</span>
err <span class="token operator">=</span> <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_C<span class="token punctuation">)</span><span class="token punctuation">;</span>
</pre><p><strong>Note: this code is for a slightly different example, use it only as an example of <code>cuda&lt;method&gt;</code> methods</strong></p>
<h2 class="mume-header" id="cuda-error-handling">CUDA Error Handling</h2>

<p>The only way to check hat things are working correctly on the GPU is the check the error return values. <strong>Check them every time</strong></p>
<pre data-role="codeBlock" data-info="c" class="language-c"><span class="token keyword">if</span> <span class="token punctuation">(</span>err <span class="token operator">!=</span> cudaSuccess<span class="token punctuation">)</span><span class="token punctuation">{</span>
    <span class="token comment">// handler</span>
<span class="token punctuation">}</span>
</pre><ul>
<li>Kernel functions don&apos;t return error numbers. However, after it has finished you can call <code>err = cudaGetLastError();</code> to get the error number if one occurred.</li>
<li>Since kernel functions can run in parallel with host functions, if ou call <code>cudaGetLastError()</code> before the kernel function finishes, the rror may only occur after you requested the error.</li>
<li>If you really want to avoid this call <code>cudaDeviceSyncronize()</code>
<ul>
<li>But avoid this as it is very inefficient.</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="timing-host-code-with-host-timers">TIming Host Code with Host Timers</h2>

<ul>
<li>
<p>Typically we want to time both the sequential code (on the host) and the parallel code (on the GPU).</p>
</li>
<li>
<p>The general approach to time the <strong>Host</strong> code is:</p>
</li>
</ul>
<pre data-role="codeBlock" data-info="c" class="language-c"><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;cuda_runtime.h&gt;</span></span>
<span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;helper_cuda.h&gt;</span></span>
<span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;helper_functions.h&gt;</span></span>

StopWatchInterface <span class="token operator">*</span>timer <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
<span class="token function">sdkCreateTimer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">sdkStartTimer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/* The Host code that is to be timed*/</span>

<span class="token function">sdkStopTimer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">double</span> h_msecs <span class="token operator">=</span> <span class="token function">sdkGetTimerValue</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">sdkDeleteTimer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>

</pre><ul>
<li>In general do <strong>NOT</strong> use host timers to time GPU code. They are much less accurate.</li>
<li>However, if you <strong>have to</strong> time the <strong>Host and GPU</strong> code using host timers the pattern is:</li>
</ul>
<pre data-role="codeBlock" data-info="c" class="language-c"><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;cuda_runtime.h&gt;</span></span>
<span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;helper_cuda.h&gt;</span></span>
<span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;helper_functions.h&gt;</span></span>

StopWatchInterface <span class="token operator">*</span>timer <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
<span class="token function">sdkCreateTimer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">sdkStartTimer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/* Host + GPU code that is to be timed */</span>

<span class="token function">cudaDeviceSyncronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">sdkStopTimer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">double</span> h_msecs <span class="token operator">=</span> <span class="token function">sdkGetTimerValue</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">sdkDeleteTimter</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>timer<span class="token punctuation">)</span><span class="token punctuation">;</span>

</pre><ul>
<li>The best way to time GPU code is to insert an <strong>event</strong> into the GPU execution stream before and after the code to time and get the elapsed time from them.</li>
</ul>
<pre data-role="codeBlock" data-info="c" class="language-c">cudaEvent_t start<span class="token punctuation">,</span> stop<span class="token punctuation">;</span>
<span class="token keyword">float</span> m_secs<span class="token punctuation">;</span> 
<span class="token function">cudaEventCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>start<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaEventCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stop<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>start <span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/* Call GPU kernel(s) */</span>

<span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>stop<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaEventSyncronize</span><span class="token punctuation">(</span>stop<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">cudaEventElapsedTime</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_msecs<span class="token punctuation">,</span> start<span class="token punctuation">,</span> stop<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaEventDestroy</span><span class="token punctuation">(</span>start<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaEventDestroy</span><span class="token punctuation">(</span>stop<span class="token punctuation">)</span><span class="token punctuation">;</span>
</pre>
      </div>
      <div class="md-sidebar-toc"><ul>
<li><a href="#lecture-7">Lecture 7</a>
<ul>
<li><a href="#2-types-of-parallelism">2 Types of Parallelism</a></li>
<li><a href="#latency-vs-throughput">Latency vs. Throughput</a><br>
- <a href="#fig-1-von-neumann-architecture">Fig. 1. Von Neumann Architecture</a><br>
- <a href="#fig-2-von-neumann-architecture-for-gpu">Fig. 2. Von Neumann Architecture for GPU</a></li>
<li><a href="#compiling-for-cuda">Compiling for CUDA</a></li>
<li><a href="#vectoradd-trivial-example">VectorAdd - trivial example</a></li>
<li><a href="#cpu-computational-unit-structure">CPU computational unit structure</a></li>
<li><a href="#cuda-thread-issues">CUDA thread issues</a></li>
<li><a href="#cuda-thread-organisation">CUDA thread organisation</a></li>
<li><a href="#invoking-kernel-functions">Invoking Kernel Functions</a></li>
<li><a href="#inside-kernel-functions">Inside Kernel Functions</a></li>
<li><a href="#grid-and-block-dimensionalities">Grid and Block Dimensionalities</a></li>
<li><a href="#device-global-memory">Device Global Memory</a></li>
<li><a href="#cuda-error-handling">CUDA Error Handling</a></li>
<li><a href="#timing-host-code-with-host-timers">TIming Host Code with Host Timers</a></li>
</ul>
</li>
</ul>
</div>
      <a id="sidebar-toc-btn">&#x2261;</a>
    
    
    
    
    
    
    
    
<script>

var sidebarTOCBtn = document.getElementById('sidebar-toc-btn')
sidebarTOCBtn.addEventListener('click', function(event) {
  event.stopPropagation()
  if (document.body.hasAttribute('html-show-sidebar-toc')) {
    document.body.removeAttribute('html-show-sidebar-toc')
  } else {
    document.body.setAttribute('html-show-sidebar-toc', true)
  }
})
</script>
      
  
    </body></html>